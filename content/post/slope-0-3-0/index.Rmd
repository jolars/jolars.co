---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: "SLOPE 0.3.0"
subtitle: ""
summary: "A new version of SLOPE is out that fixes some issues related to model tuning."
authors: [Johan Larsson]
tags: [R, SLOPE, regularization, generalized linear models]
categories: [R]
date: 2020-06-01T20:53:01+02:00
lastmod: 2020-06-01T20:53:01+02:00
featured: true
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: ""
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: [SLOPE]
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  dev.args = list(pointsize = 8),
  crop = TRUE,
  fig.width = 3.5,
  fig.height = 2.9
)

options(digits = 3)
```

## SLOPE 0.3.0

A new version of the SLOPE package for R is 
[out on CRAN](https://CRAN.R-project.org/package=SLOPE). This release only
boasts a couple of new features but does introduce a considerable
number of **breaking changes**.

### Standardization of `alpha` (formerly `sigma`)

Chief among the changes in SLOPE 0.3.0 is that the regularization
sequence is now standardized so that it is independent on the
number of observations. Previously, this was only the case
when the predictors were standardized using the standard deviation
and not when using the \(\ell_1\) or \(\ell_2\) norms. And even then,
this standardization was not completely correct due to the presence
of the \(n-1\) denominator in the sample standard deviation (which was
previously used).

To be precise, the objective minimized in SLOPE is now, for \(\ell_2\) 
standardization,
\[ 
  \frac{1}{s}f(\beta) + \alpha \sum_{j=1}^p \lambda_j |\beta|_{(j)},
\]
where
\[
s=
\begin{cases}
  1        & \ell_1,\\
  \sqrt{n} & \ell_2,\\
  n        & \text{standard deviation}.
\end{cases}
\]
Prior to this version, \(s\) was always \(n\). Moreover, 
standard

For standard deviation-scaling and no scaling, it is now
\[
  f(\beta) + \alpha n \sum_{j=1}^p \lambda_j |\beta|_{(j)},
\]
which is precisely the form used in SLOPE 0.2.0, but now
setting `scale = "sd"` in the call to `SLOPE()` uses standardization with
the population standard deviation, instead of the sample standard deviation.
This is exactly the form used in the popular glmnet package for elastic
net regularized methods.

Finally, for \(\ell_1\) norm scaling, the objective used is 
\[
  f(\beta) + \alpha \sum_{j=1}^p \lambda_j |\beta|_{(j)},
\]
i.e. no scaling is applied. 




